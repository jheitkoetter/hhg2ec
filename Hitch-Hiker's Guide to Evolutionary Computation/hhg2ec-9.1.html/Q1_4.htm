<HTML><HEAD> <TITLE> Q1.4 - HHGT Evolutionary Computation</TITLE></HEAD><BODY>
<P>

<H1><A href=Q1_4.htm>Q1.4</A>: What's a Classifier System (CFS)?</H1>
<P>
<P>

<H2><A NAME="The name of the Game">
The name of the Game</A></H2>
<P> First, a word on naming conventions is due, for no other paradigm of
<font size=-1> <A href="Q99_E.htm#EC">EC</A></font>
has undergone more changes to its <I>name space</I> than this one.  Initially, Holland called
his cognitive models "Classifier Systems" abbrv. with
<font size=-1> <A href="Q99_C.htm#CS">CS</A>,</font>
and sometimes
<font size=-1> <A href="Q99_C.htm#CFS">CFS</A>,</font>
as can be found in <A href="Q10_2.htm#:GOLD89">[GOLD89]</a>.
<P> Whence Riolo came into play in 1986 and Holland added a reinforcement component to the overall
design of a CFS, that emphasized its ability to learn. So, the word "learning" was prepended to the
name, to make: "Learning Classifier Systems" (abbrv. to
<font size=-1> <A href="Q99_L.htm#LCS">LCS</A>).</font>
On October 6-9, 1992 the "1st Inter'l Workshop on Learning Classifier Systems" took place at the
NASA Johnson Space Center, Houston, TX.  A summary of this "summit" of all leading researchers in
LCS can be found on
<font size=-1> <A href="Q99_E.htm#ENCORE">ENCORE</A></font>
(See <A href=Q15_3.htm>Q15.3</A>) in file <B>CFS/papers/lcs92.ps.gz</B>
<P> Today, the story continues, LCSs are sometimes subsumed under a "new" machine learning paradigm
called "Evolutionary Reinforcement Learning" or ERL for short, incorporating LCSs, "Q-Learning",
devised by Watkins (1989), and a paradigm of the same name, devised by Ackley and Littman <A
href="Q12.htm#:ALIFEIII">[ALIFEIII]</a>.
<P> And then, this latter statement is really somewhat confusing, as Marco Dorigo has pointed out in
a letter to editors of this guide, since Q-Learning has no evolutionary component. So please let the
Senior Editor explain: When I wrote this part of the guide, I just had in mind that Q-Learning would
make for a pretty good replacement of Holland's bucket-brigade algorithm, so I used this litte
speculation to see what comes out of it; in early December 95, almost two years later, it has
finally caught Marco's attention. But meanwhile, I have been proven right: Wilson has suggested to
use Q-Learning in
<font size=-1> <A href="Q99_C.htm#CLASSIFIER SYSTEM">CLASSIFIER SYSTEM</A></font>
(Wilson 1994) and Dorigo &amp; Bersini (1994) have shown that Q-Learning and the bucket-brigade are
truly equivalent concepts.
<P> We would therefore be allowed to call a CFS that uses Q-Learning for rule discovery, rather than
a bucket-brigade, a Q-CFS, Q-LCS, or Q-CS; in any case would the result be subsumed under the term
ERL, even if Q-Learning itself is not an
<font size=-1> <A href="Q99_E.htm#EVOLUTIONARY ALGORITHM">EVOLUTIONARY ALGORITHM</A>!</font>
<P> Interestingly, Wilson called his system <B>ZCS</B> (apparantly no "Q" inside), while
Dorigo &amp; Bersini called their system a <B>D-Max-VSCS,</B> or "discounted max very simple
classifier system" (and if you know Q-Learning at least the <B>D-Max</B> part of the name
will remind you of that algorithm).  The latter paper can be found on Encore (see <A href=Q15_3.htm>Q15.3</A>) in file
<B>CFS/papers/sab94.ps.gz</B>
<P> And by the way in <A href="Q1_4.htm#:HOLLAND95">[HOLLAND95]</a> the term "classifier system" is
not used anymore. You cannot find it in the index. Its a gone!  Holland now stresses the adaptive
component of his invention, and simply calls the resulting systems <B>adaptive agents.</B>
These agents are then implemented within the framework of his recent invention called <B>ECHO.
</B> (See
<A href="http://www.santafe.edu/projects/echo" >http://www.santafe.edu/projects/echo</A> for more.)
<P> Alwyn Barry's LCS Web has a great deal of information on LCS. See:
<A href="http://www.csm.uwe.ac.uk/~ambarry/LCSWEB/" >http://www.csm.uwe.ac.uk/~ambarry/LCSWEB/</A>
<P>

<H2><A NAME="On Schema Processors and ANIMATS">
On Schema Processors and ANIMATS</A></H2>
<P> So, to get back to the question above, "What are CFSs?", we first might answer, "Well, there are
many interpretations of Holland's ideas...what do you like to know in particular?"  And then we'd
start with a recitation from <A href="Q10_3.htm#:HOLLAND75">[HOLLAND75]</a>, <A
href="Q10_3.htm#:HOLLAND92">[HOLLAND92]</a>, and explain all the
<font size=-1> <A href="Q99_S.htm#SCHEMA">SCHEMA</A></font>
processors, the broadcast language, etc.  But, we will take a more comprehensive, and intuitive way
to understand what
<font size=-1> <A href="Q99_C.htm#CLASSIFIER SYSTEM">CLASSIFIER SYSTEM</A>s</font>
are all about.
<P> The easiest road to explore the very nature of classifier systems, is to take the animat (ANIMAl
+
<font size=-1> <A href="Q99_R.htm#ROBOT">ROBOT</A></font>
= ANIMAT) "lane" devised by Booker (1982) and later studied extensively by Wilson (1985), who also
coined the term for this approach. Work continues on animats but is often regarded as
<font size=-1> <A href="Q99_A.htm#ARTIFICIAL LIFE">ARTIFICIAL LIFE</A></font>
rather than
<font size=-1> <A href="Q99_E.htm#EVOLUTIONARY COMPUTATION">EVOLUTIONARY COMPUTATION</A>.</font>
This thread of research has even its own conference series: "Simulation of Adaptive Behavior (SAB)"
(cf <A href=Q12.htm>Q12</A>), including other notions from machine learning, connectionist learning, evolutionary
robotics, etc.  [NB: the latter is obvious, if an animat lives in a digital microcosm, it can be put
into the real world by implantation into an autonomous robot vehicle, that has sensors/detectors
(camera eyes, whiskers, etc.) and effectors (wheels, robot arms, etc.); so all that's needed is to
use our algorithm as the "brain" of this vehicle, connecting the hardware parts with the software
learning component.  For a fascinating intro to the field see, e.g. Braitenberg (1984)]
<P> classifier systems, however, are yet another offspring of John Holland's aforementioned book,
and can be seen as one of the early applications of
<font size=-1> <A href="Q99_G.htm#GA">GA</A>s,</font>
for
<font size=-1> <A href="Q99_C.htm#CFS">CFS</A>s</font>
use this
<font size=-1> <A href="Q99_E.htm#EVOLUTIONARY ALGORITHM">EVOLUTIONARY ALGORITHM</A></font>
to adapt their behavior toward a changing
<font size=-1> <A href="Q99_E.htm#ENVIRONMENT">ENVIRONMENT</A>,</font>
as is explained below in greater detail.
<P> Holland envisioned a cognitive system capable of classifying the goings on in its environment,
and then reacting to these goings on appropriately. So what is needed to build such a system?
Obviously, we need (1) an environment; (2) receptors that tell our system about the goings on; (3)
effectors, that let our system manipulate its environment; and (4) the system itself, conveniently a
"black box" in this first approach, that has (2) and (3) attached to it, and "lives" in (1).
<P> In the animat approach, (1) usually is an artificially created digital world, e.g. in Booker's
Gofer system, a 2 dimensional grid that contains "food" and "poison".  And the Gofer itself, that
walks across this grid and tries (a) to learn to distinguish between these two items, and (b)
survive well fed.
<P> Much the same for Wilson's animat, called "*". Yes, its just an asterisk, and a "Kafka-esque
naming policy" is one of the sign posts of the whole field; e.g. the first implementation by Holland
and Reitmann 1978 was called CS-1, (cognitive system 1); Smith's Poker player LS-1 (1980) followed
this "convention". Riolo's 1988
<font size=-1> <A href="Q99_L.htm#LCS">LCS</A></font>
implementations on top of his CFS-C library (cf <A href=Q20.htm>Q20</A>), were dubbed FSW-1 (Finite State World 1), and
LETSEQ-1 (LETter SEQuence predictor 1).
<P> So from the latter paragraph we can conclude that environment can also mean something completely
different (e.g. an infinite stream of letters, time serieses, etc.) than in the animat approach, but
anyway; we'll stick to it, and go on.
<P> Imagine a very simple animat, e.g. a simplified model of a frog.  Now, we know that frogs live
in (a) Muppet Shows, or (b) little ponds; so we chose the latter as our demo environment (1); and
the former for a non-Kafka-esque name of our model, so let's dub it "Kermit".
<P> Kermit has eyes, i.e. sensorial input detectors (2); hands and legs, i.e.  environment-
manipulating effectors (3); is a spicy-fly-detecting-and-eating device, i.e. a frog (4); so we got
all the 4 pieces needed.
<P>

<H2><A NAME="Inside the Black Box">
Inside the Black Box</A></H2>
<P> The most primitive "black box" we can think of is a computer.  It has inputs (2), and outputs
(3), and a message passing system inbetween, that converts (i.e., <I>computes</I>), certain input
messages into output messages, according to a set of rules, usually called the "program" of that
computer.  From the theory of computer science, we now borrow the simplest of all program
structures, that is something called "production system" or PS for short.  A PS has been shown to be
computationally complete by Post (1943), that's why it is sometimes called a "Post System", and
later by Minsky (1967).  Although it merely consists of a set of if-then rules, it still resembles a
full-fledged computer.
<P> We now term a single "if-then" rule a "classifier", and choose a representation that makes it
easy to manipulate these, for example by encoding them into binary strings.  We then term the set of
classifiers, a "classifier population", and immediately know how to breed new rules for our system:
just use a
<font size=-1> <A href="Q99_G.htm#GA">GA</A></font>
to generate new rules/classifiers from the current
<font size=-1> <A href="Q99_P.htm#POPULATION">POPULATION</A>!</font>
<P> All that's left are the messages floating through the black box.  They should also be simple
strings of zeroes and ones, and are to be kept in a data structure, we call "the message list".
<P> With all this given, we can imagine the goings on inside the black box as follows: The input
interface (2) generates messages, i.e., 0/1 strings, that are written on the message list. Then
these messages are matched against the condition-part of all classifiers, to find out which actions
are to be triggered.  The message list is then emptied, and the encoded actions, themselves just
messages, are posted to the message list.  Then, the output interface (3) checks the message list
for messages concerning the effectors. And the cycle restarts.
<P> Note, that it is possible in this set-up to have "internal messages", because the message list
is not emptied after (3) has checked; thus, the input interface messages are <I>added</I> to
the initially empty list. (cf Algorithm
<font size=-1> <A href="Q99_C.htm#CFS">CFS</A>,</font>
<font size=-1> <A href="Q99_L.htm#LCS">LCS</A></font>
below)
<P> The general idea of the CFS is to start from scratch, i.e., from <I>tabula rasa</I>
(without any knowledge) using a randomly generated classifier population, and let the system learn
its program by induction, (cf Holland et al. 1986), this reduces the input stream to recurrent input
patterns, that must be repeated over and over again, to enable the animat to classify its current
situation/context and react on the goings on appropriately.
<P>

<H2><A NAME="What does it need to be a frog?">
What does it need to be a frog?</A></H2>
<P> Let's take a look at the behavior emitted by Kermit. It lives in its digital microwilderness
where it moves around randomly.  [NB: This seemingly "random" behavior is not that random at all;
for more on instinctive, i.e., innate behavior of non-artificial animals see, e.g.  Tinbergen
(1951)]
<P> Whenever a small flying object appears, that has no stripes, Kermit should eat it, because its
very likely a spicy fly, or other flying insect.  If it has stripes, the insect is better left
alone, because Kermit had better not bother with wasps, hornets, or bees.  If Kermit encounters a
large, looming object, it immediately uses its effectors to jump away, as far as possible.
<P> So, part of these behavior patterns within the "pond world", in
<font size=-1> <A href="Q99_A.htm#AI">AI</A></font>
sometimes called a "frame," from traditional knowledge representation techniques, Rich (1983), can
be expressed in a set of "if &lt;condition&gt; then &lt;action&gt;" rules, as follows:
<P>
<PRE>

     IF small, flying object to the left THEN send @
     IF small, flying object to the right THEN send %
     IF small, flying object centered THEN send $
     IF large, looming object THEN send !
     IF no large, looming object THEN send *
     IF * and @ THEN move head 15 degrees left
     IF * and % THEN move head 15 degrees right
     IF * and $ THEN move in direction head pointing
     IF ! THEN move rapidly away from direction head pointing
</PRE>

<P> Now, this set of rules has to be encoded for use within a
<font size=-1> <A href="Q99_C.htm#CLASSIFIER SYSTEM">CLASSIFIER SYSTEM</A>.</font>
A possible encoding of the above rule set in CFS-C (Riolo) classifier terminology. The condition
part consists of two conditions, that are combined with a logical AND, thus must be met both to
trigger the associated action. This structure needs a NOT operation, (so we get NAND, and know from
hardware design, that we can build any computer solely with NANDs), in CFS-C this is denoted by the
`~' prefix character (rule #5).
<P>
<PRE>

<B>  IF             THEN</B>
      0000,  00 00  00 00
      0000,  00 01  00 01
      0000,  00 10  00 10
      1111,  01 ##  11 11
     ~1111,  01 ##  10 00
      1000,  00 00  01 00
      1000,  00 01  01 01
      1000,  00 10  01 10
      1111,  ## ##  01 11
</PRE>

<P> Obviously, string `0000' denotes <I>small,</I> and `00' in the fist part of the second
column, denotes <I>flying.</I> The last two bits of column #2 encode the direction of the
object approaching, where `00' means <I>left,</I> `01' means <I>right,</I> etc.
<P> In rule #4 a the "don't care symbol" `#' is used, that matches `1' and `0', i.e., the position
of the large, looming object, is completely arbitrary. A simple fact, that can save Kermit's
(artificial) life.
<P>

<H2><A NAME="PSEUDO CODE (Non-Learning CFS)">
PSEUDO CODE (Non-Learning CFS)</A></H2>
<PRE>

<B>Algorithm</B> CFS <B>is</B>
<P>
<I>  // start with an initial time</I>
     t := 0;
<P>
<I>  // an initially empty message list</I>
     initMessageList ML (t);
<P>
<I>  // and a randomly generated population of classifiers</I>
     initClassifierPopulation P (t);
<P>
<I>  // test for cycle termination criterion (time, fitness, etc.)</I>
     <B>while</B> not done <B>do</B>
<P>
<I>       // increase the time counter</I>
	  t := t + 1;
<P>
<I>       // 1. detectors check whether input messages are present</I>
	  ML := readDetectors (t);
<P>
<I>       // 2. compare ML to the classifiers and save matches</I>
	  ML' := matchClassifiers ML,P (t);
<P>
<I>       // 3. process new messages through output interface</I>
	  ML := sendEffectors ML' (t);
<B>  od</B>
<B>end</B> CFS.
</PRE>

<P> To convert the previous, non-learning
<font size=-1> <A href="Q99_C.htm#CFS">CFS</A></font>
into a learning
<font size=-1> <A href="Q99_C.htm#CLASSIFIER SYSTEM">CLASSIFIER SYSTEM</A>,</font>
<font size=-1> <A href="Q99_L.htm#LCS">LCS</A>,</font>
as has been proposed in Holland (1986), it takes two steps:
<UL>
 <P> (1) the major cycle has to be changed such that the activation of each classifier depends on
 some additional parameter, that can be modified as a result of experience, i.e. reinforcement from
 the
 <font size=-1> <A href="Q99_E.htm#ENVIRONMENT">ENVIRONMENT</A>;</font>

<P>
 (2) and/or change the contents of the classifier list, i.e., generate new classifiers/rules, by
 removing, adding, or combining condition/action-parts of existing classifiers.
</UL>
<P> The algorithm thus changes accordingly:
<P>

<H2><A NAME="PSEUDO CODE (Learning CFS)">
PSEUDO CODE (Learning CFS)</A></H2>
<PRE>

<B>Algorithm</B> LCS <B>is</B>
<P>
<I>  // start with an initial time</I>
     t := 0;
<P>
<I>  // an initially empty message list</I>
     initMessageList ML (t);
<P>
<I>  // and a randomly generated population of classifiers</I>
     initClassifierPopulation P (t);
<P>
<I>  // test for cycle termination criterion (time, fitness, etc.)</I>
     <B>while</B> not done <B>do</B>
<P>
<I>       // increase the time counter</I>
	  t := t + 1;
<P>
<I>       // 1. detectors check whether input messages are present</I>
	  ML := readDetectors (t);
<P>
<I>       // 2. compare ML to the classifiers and save matches</I>
	  ML' := matchClassifiers ML,P (t);
<P>
<I>       // 3. highest bidding classifier(s) collected in ML' wins the</I>
<I>       // "race" and post the(ir) message(s)</I>
	  ML' := selectMatchingClassifiers ML',P (t);
<P>
<I>       // 4. tax bidding classifiers, reduce their strength</I>
	  ML' := taxPostingClassifiers ML',P (t);
<P>
<I>       // 5. effectors check new message list for output msgs</I>
	  ML := sendEffectors ML' (t);
<P>
<I>       // 6. receive payoff from environment (REINFORCEMENT)</I>
	  C := receivePayoff (t);
<P>
<I>       // 7. distribute payoff/credit to classifiers (e.g. BBA)</I>
	  P' := distributeCredit C,P (t);
<P>
<I>       // 8. Eventually (depending on t), an EA (usually a GA) is</I>
<I>       // applied to the classifier population</I>
	  <B>if</B> criterion <B>then</B>
	       P := generateNewRules P' (t);
	  <B>else</B>
	       P := P'
<B>  od</B>
<B>end</B> LCS.
</PRE>

<P>

<H2><A NAME="What's the problem with CFSs?">
What's the problem with CFSs?</A></H2>
<P> Just to list the currently known problems that come with
<font size=-1> <A href="Q99_C.htm#CFS">CFS</A>s,</font>
would take some additional pages; therefore only some interesting papers dealing with unresolved
riddles are listed; probably the best paper containing most of these is the aforementioned summary
of the
<font size=-1> <A href="Q99_L.htm#LCS">LCS</A></font>
Workshop:
<P> Smith, R.E. (1992) "A report on the first Inter'l Workshop on LCSs" avail. from
<font size=-1> <A href="Q99_E.htm#ENCORE">ENCORE</A></font>
(See <A href=Q15_3.htm>Q15.3</A>) in file <B>CFS/papers/lcs92.ps.gz</B>
<P> Other noteworthy critiques on LCSs include:
<P> Wilson, S.W. (1987) "Classifier Systems and the Animat Problem" Machine Learning, 2.
<P> Wilson, S.W. (1988) "Bid Competition and Specificity Reconsidered" Complex Systems,
2(5):705-723.
<P> Wilson, S.W. &amp; Goldberg, D.E. (1989) "A critical review of classifier systems" <A
href="Q12.htm#:ICGA89">[ICGA89]</a>, 244-255.
<P> Goldberg, D.E., Horn, J. &amp; Deb, K. (1992) "What makes a problem hard for a classifier
system?"  (containing the Goldberg citation below) is also available from Encore (See <A href=Q15_3.htm>Q15.3</A>) in file
<B>CFS/papers/lcs92-2.ps.gz</B>
<P> Dorigo, M. (1993) "Genetic and Non-genetic Operators in ALECSYS" Evolutionary Computation,
1(2):151-164.  The technical report, the journal article is based on is avail. from Encore (See
<A href=Q15_3.htm>Q15.3</A>) in file <B>CFS/papers/icsi92.ps.gz</B>
<P> Smith, R.E. Forrest, S. &amp; Perelson, A.S. (1993) "Searching for Diverse, Cooperative
<font size=-1> <A href="Q99_P.htm#POPULATION">POPULATION</A>s</font>
with Genetic Algorithms" Evolutionary Computation, 1(2):127-149.
<P>

<H2><A NAME="Conclusions?">
Conclusions?</A></H2>
<P> Generally speaking:  "There's much to do in
<font size=-1> <A href="Q99_C.htm#CFS">CFS</A></font>
research!"
<P> No other notion of
<font size=-1> <A href="Q99_E.htm#EC">EC</A></font>
provides more space to explore and if you are interested in a PhD in the field, you might want to
take a closer look at CFS.  However, be warned!, to quote Goldberg: "classifier systems are a
quagmire---a glorious, wondrous, and <I> inventing quagmire, but a quagmire nonetheless."</I>
<P> References
<P> Booker, L.B. (1982) "Intelligent behavior as an adaption to the  task environment" PhD
Dissertation, Univ. of Michigan, Logic of Computers Group, Ann Arbor, MI.
<P> Braitenberg, V. (1984) "Vehicles: Experiments in Synthetic Psychology" Boston, MA: MIT Press.
<P> Dorigo M. &amp; H. Bersini (1994). "A Comparison of Q-Learning and Classifier Systems."
Proceedings of From Animals to Animats, Third International Conference on
<font size=-1> <A href="Q99_S.htm#SIMULATION">SIMULATION</A></font>
of Adaptive Behavior (SAB94), Brighton, UK, D.Cliff, P.Husbands, J.-A.Meyer and S.W.Wilson (Eds.),
MIT Press, 248-255.
<A href="http://iridia.ulb.ac.be/dorigo/dorigo/conferences/IC.11-SAB94.ps.gz"
>http://iridia.ulb.ac.be/dorigo/dorigo/conferences/IC.11-SAB94.ps.gz</A>
<P> Holland, J.H. (1986) "Escaping Brittleness: The possibilities of general-purpose learning
algorithms applied to parallel rule-based systems". In: R.S. Michalski, J.G. Carbonell &amp; T.M.
Mitchell (eds), Machine Learning: An Artificial Intelligence approach, Vol II, 593-623, Los Altos,
CA: Morgan Kaufman.
<P> Holland, J.H., et al. (1986) "Induction: Processes of Inference, Learning, and Discovery",
Cambridge, MA: MIT Press.
<P> Holland, J.H. (1992) "Adaptation in natural and artificial systems" Boston, MA: MIT Press.
<P> Holland, J.H. (1995) "Hidden Order: How adaptation builds complexity" Reading, MA: Addison-
Wesley. <A NAME=":HOLLAND95">[HOLLAND95]:</a>
<P> Holland, J.H. &amp; Reitman, J.S. (1978) "Cognitive Systems based on Adaptive Algorithms" In
D.A. Waterman &amp; F.Hayes-Roth, (eds) Pattern-directed inference systems. NY: Academic Press.
<P> Minsky, M.L. (1961) "Steps toward Artificial Intelligence" Proceedings IRE, 49, 8-30. Reprinted
in E.A. Feigenbaum &amp; J. Feldman (eds) Computers and Thought, 406-450, NY: McGraw-Hill, 1963.
<P> Minsky, M.L. (1967) "Computation: Finite and Infinite Machines" Englewood Cliffs, NJ: Prentice-
Hall.
<P> Post, Emil L. (1943) "Formal reductions of the general combinatorial decision problem" American
Journal of Mathematics, 65, 197-215.
<P> Rich, E. (1983) "Artificial Intelligence" NY: McGraw-Hill.
<P> Tinbergen, N. (1951) "The Study of Instinct" NY: Oxford Univ. Press.
<P> Watkins, C. (1989) "Learning from Delayed Rewards" PhD Dissertation, Department of Psychology,
Cambridge Univ., UK.
<P> Wilson, S.W. (1985) "Knowledge growth in an artificial animal" in <A
href="Q12.htm#:ICGA85">[ICGA85]</a>, 16-23.
<P> Wilson, S.W. (1994) "ZCS: a zeroth level classifier system" in EC 2(1), 1-18.
<HR><P><center><A href="Q1_3.htm">[Previous question]</A>
<A href="Q1_5.htm">[Next question]</A>
<A href="top.htm">[HHGTEC main contents page]</A>
<P><i><font size=-1>
<a href="mistakes.htm">Mistakes in this page?</a><br>
Hitch Hiker's Guide to Evolutionary Computation,
Issue 9.1, released 12 April 2001 <br>
Copyright &copy; 1993-2001 by J. Heitk&ouml;tter and
D. Beasley, all rights reserved.
</i></center></font></BODY></HTML>





















































